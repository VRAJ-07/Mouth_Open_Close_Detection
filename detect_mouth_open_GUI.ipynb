{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a673402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
      "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Click>=6.0 in /opt/anaconda3/lib/python3.9/site-packages (from face_recognition) (8.0.4)\n",
      "Collecting dlib>=19.7 (from face_recognition)\n",
      "  Using cached dlib-19.24.2.tar.gz (11.8 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/anaconda3/lib/python3.9/site-packages (from face_recognition) (1.21.6)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.9/site-packages (from face_recognition) (9.2.0)\n",
      "Building wheels for collected packages: dlib, face-recognition-models\n",
      "  Building wheel for dlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlib: filename=dlib-19.24.2-cp39-cp39-macosx_10_13_x86_64.whl size=3626252 sha256=693a009a49bd7500e630416459e73127742a5af044d0fd5d28fd23894a638628\n",
      "  Stored in directory: /Users/HEMANT/Library/Caches/pip/wheels/f7/ae/0e/3478eae12f6aed0e3d4880147ca855ba5d58f2e1098c73ab5f\n",
      "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566170 sha256=615a7c4a280835798e44610210adac57ee30b2da07febba13940f009efc3c144\n",
      "  Stored in directory: /Users/HEMANT/Library/Caches/pip/wheels/22/a8/60/4a2aeb763d63f50190f4c4e07069a22245347eeafdb3a67551\n",
      "Successfully built dlib face-recognition-models\n",
      "Installing collected packages: face-recognition-models, dlib, face_recognition\n",
      "Successfully installed dlib-19.24.2 face-recognition-models-0.3.0 face_recognition-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52caf969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mouth_open_algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0fe00",
   "metadata": {},
   "source": [
    "# For Live Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca87658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@3.353] global cap.cpp:645 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.9.0) /private/var/folders/n0/slzyhy8s3238zz8_3flb77r00000gn/T/pip-install-vny5s0t7/opencv-python_8dd1aa98c20c4a5195ae46b743f8452a/opencv/modules/videoio/src/cap_images.cpp:430: error: (-215:Assertion failed) !filename_pattern.empty() in function 'open'\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_lip_height: 13.03, bottom_lip_height: 18.07, mouth_height: 3.05, min*ratio: 6.51\n",
      "top_lip_height: 11.67, bottom_lip_height: 20.02, mouth_height: 0.33, min*ratio: 5.83\n",
      "top_lip_height: 11.67, bottom_lip_height: 18.01, mouth_height: 1.80, min*ratio: 5.83\n",
      "top_lip_height: 11.00, bottom_lip_height: 18.01, mouth_height: 3.60, min*ratio: 5.50\n",
      "top_lip_height: 13.34, bottom_lip_height: 19.34, mouth_height: 1.47, min*ratio: 6.67\n",
      "top_lip_height: 10.35, bottom_lip_height: 16.69, mouth_height: 1.82, min*ratio: 5.18\n",
      "top_lip_height: 7.33, bottom_lip_height: 12.36, mouth_height: 15.01, min*ratio: 3.67\n",
      "top_lip_height: 12.00, bottom_lip_height: 16.01, mouth_height: 1.14, min*ratio: 6.00\n",
      "top_lip_height: 11.33, bottom_lip_height: 17.02, mouth_height: 1.41, min*ratio: 5.67\n",
      "top_lip_height: 10.68, bottom_lip_height: 15.02, mouth_height: 2.33, min*ratio: 5.34\n",
      "top_lip_height: 12.00, bottom_lip_height: 17.70, mouth_height: 0.33, min*ratio: 6.00\n",
      "top_lip_height: 6.39, bottom_lip_height: 15.72, mouth_height: 42.01, min*ratio: 3.20\n",
      "top_lip_height: 7.36, bottom_lip_height: 14.34, mouth_height: 32.34, min*ratio: 3.68\n",
      "top_lip_height: 11.33, bottom_lip_height: 16.02, mouth_height: 1.28, min*ratio: 5.67\n",
      "top_lip_height: 11.40, bottom_lip_height: 13.73, mouth_height: 2.47, min*ratio: 5.70\n",
      "top_lip_height: 11.69, bottom_lip_height: 14.40, mouth_height: 1.55, min*ratio: 5.85\n",
      "top_lip_height: 11.37, bottom_lip_height: 16.05, mouth_height: 1.69, min*ratio: 5.68\n",
      "top_lip_height: 11.01, bottom_lip_height: 13.35, mouth_height: 0.80, min*ratio: 5.51\n",
      "top_lip_height: 12.01, bottom_lip_height: 13.40, mouth_height: 1.00, min*ratio: 6.01\n",
      "top_lip_height: 12.03, bottom_lip_height: 14.40, mouth_height: 4.12, min*ratio: 6.01\n",
      "top_lip_height: 12.68, bottom_lip_height: 17.02, mouth_height: 3.75, min*ratio: 6.34\n",
      "top_lip_height: 12.69, bottom_lip_height: 16.02, mouth_height: 3.33, min*ratio: 6.35\n",
      "top_lip_height: 11.67, bottom_lip_height: 16.01, mouth_height: 6.69, min*ratio: 5.83\n",
      "top_lip_height: 11.38, bottom_lip_height: 15.07, mouth_height: 5.73, min*ratio: 5.69\n",
      "top_lip_height: 12.03, bottom_lip_height: 16.68, mouth_height: 1.67, min*ratio: 6.01\n",
      "top_lip_height: 13.00, bottom_lip_height: 18.01, mouth_height: 2.47, min*ratio: 6.50\n",
      "top_lip_height: 11.05, bottom_lip_height: 14.36, mouth_height: 4.70, min*ratio: 5.52\n",
      "top_lip_height: 12.69, bottom_lip_height: 17.01, mouth_height: 3.71, min*ratio: 6.35\n",
      "top_lip_height: 12.67, bottom_lip_height: 16.04, mouth_height: 3.80, min*ratio: 6.33\n",
      "top_lip_height: 12.36, bottom_lip_height: 16.05, mouth_height: 5.84, min*ratio: 6.18\n",
      "top_lip_height: 12.06, bottom_lip_height: 16.73, mouth_height: 3.43, min*ratio: 6.03\n",
      "top_lip_height: 9.72, bottom_lip_height: 14.39, mouth_height: 0.33, min*ratio: 4.86\n",
      "top_lip_height: 10.71, bottom_lip_height: 16.40, mouth_height: 11.09, min*ratio: 5.36\n",
      "top_lip_height: 10.67, bottom_lip_height: 15.03, mouth_height: 12.01, min*ratio: 5.33\n",
      "top_lip_height: 9.67, bottom_lip_height: 21.02, mouth_height: 37.34, min*ratio: 4.83\n",
      "top_lip_height: 11.36, bottom_lip_height: 25.68, mouth_height: 52.19, min*ratio: 5.68\n",
      "top_lip_height: 5.69, bottom_lip_height: 13.41, mouth_height: 8.73, min*ratio: 2.85\n",
      "top_lip_height: 9.02, bottom_lip_height: 15.71, mouth_height: 7.38, min*ratio: 4.51\n",
      "top_lip_height: 9.35, bottom_lip_height: 18.68, mouth_height: 1.14, min*ratio: 4.67\n",
      "top_lip_height: 13.67, bottom_lip_height: 22.02, mouth_height: 29.49, min*ratio: 6.83\n",
      "top_lip_height: 12.35, bottom_lip_height: 21.05, mouth_height: 26.15, min*ratio: 6.17\n",
      "top_lip_height: 13.00, bottom_lip_height: 16.69, mouth_height: 1.28, min*ratio: 6.50\n",
      "top_lip_height: 9.04, bottom_lip_height: 12.03, mouth_height: 1.47, min*ratio: 4.52\n",
      "top_lip_height: 9.02, bottom_lip_height: 14.02, mouth_height: 1.47, min*ratio: 4.51\n",
      "top_lip_height: 8.68, bottom_lip_height: 14.02, mouth_height: 2.08, min*ratio: 4.34\n",
      "top_lip_height: 10.02, bottom_lip_height: 13.35, mouth_height: 0.00, min*ratio: 5.01\n",
      "top_lip_height: 9.02, bottom_lip_height: 13.36, mouth_height: 0.33, min*ratio: 4.51\n",
      "top_lip_height: 8.67, bottom_lip_height: 13.35, mouth_height: 1.75, min*ratio: 4.33\n",
      "top_lip_height: 8.35, bottom_lip_height: 15.02, mouth_height: 2.00, min*ratio: 4.18\n",
      "top_lip_height: 7.67, bottom_lip_height: 13.03, mouth_height: 2.08, min*ratio: 3.83\n",
      "top_lip_height: 7.71, bottom_lip_height: 12.74, mouth_height: 1.00, min*ratio: 3.86\n",
      "top_lip_height: 5.67, bottom_lip_height: 13.00, mouth_height: 1.75, min*ratio: 2.83\n",
      "top_lip_height: 6.00, bottom_lip_height: 12.01, mouth_height: 1.75, min*ratio: 3.00\n",
      "top_lip_height: 6.69, bottom_lip_height: 12.03, mouth_height: 1.28, min*ratio: 3.35\n",
      "top_lip_height: 10.71, bottom_lip_height: 15.07, mouth_height: 1.88, min*ratio: 5.36\n",
      "top_lip_height: 11.03, bottom_lip_height: 16.68, mouth_height: 0.00, min*ratio: 5.52\n",
      "top_lip_height: 8.38, bottom_lip_height: 13.04, mouth_height: 0.00, min*ratio: 4.19\n",
      "top_lip_height: 8.72, bottom_lip_height: 14.02, mouth_height: 0.00, min*ratio: 4.36\n",
      "top_lip_height: 10.02, bottom_lip_height: 14.02, mouth_height: 0.00, min*ratio: 5.01\n",
      "top_lip_height: 10.04, bottom_lip_height: 13.69, mouth_height: 0.67, min*ratio: 5.02\n",
      "top_lip_height: 8.33, bottom_lip_height: 14.68, mouth_height: 10.70, min*ratio: 4.17\n",
      "top_lip_height: 9.06, bottom_lip_height: 15.02, mouth_height: 9.04, min*ratio: 4.53\n",
      "top_lip_height: 8.71, bottom_lip_height: 12.69, mouth_height: 2.08, min*ratio: 4.35\n",
      "top_lip_height: 9.37, bottom_lip_height: 12.74, mouth_height: 1.96, min*ratio: 4.68\n",
      "top_lip_height: 6.72, bottom_lip_height: 12.69, mouth_height: 10.03, min*ratio: 3.36\n",
      "top_lip_height: 8.12, bottom_lip_height: 13.41, mouth_height: 8.69, min*ratio: 4.06\n",
      "top_lip_height: 9.75, bottom_lip_height: 12.71, mouth_height: 1.96, min*ratio: 4.88\n",
      "top_lip_height: 9.44, bottom_lip_height: 13.04, mouth_height: 1.96, min*ratio: 4.72\n",
      "top_lip_height: 10.70, bottom_lip_height: 16.05, mouth_height: 2.24, min*ratio: 5.35\n",
      "top_lip_height: 10.37, bottom_lip_height: 15.02, mouth_height: 1.14, min*ratio: 5.18\n",
      "top_lip_height: 13.67, bottom_lip_height: 21.01, mouth_height: 4.70, min*ratio: 6.83\n",
      "top_lip_height: 11.70, bottom_lip_height: 22.69, mouth_height: 34.34, min*ratio: 5.85\n",
      "top_lip_height: 11.03, bottom_lip_height: 21.70, mouth_height: 32.34, min*ratio: 5.52\n",
      "top_lip_height: 10.36, bottom_lip_height: 15.09, mouth_height: 3.16, min*ratio: 5.18\n",
      "top_lip_height: 11.33, bottom_lip_height: 14.35, mouth_height: 9.11, min*ratio: 5.67\n",
      "top_lip_height: 13.40, bottom_lip_height: 16.56, mouth_height: 2.43, min*ratio: 6.70\n",
      "top_lip_height: 11.36, bottom_lip_height: 17.72, mouth_height: 1.82, min*ratio: 5.68\n",
      "top_lip_height: 11.05, bottom_lip_height: 20.38, mouth_height: 34.06, min*ratio: 5.52\n",
      "top_lip_height: 8.04, bottom_lip_height: 16.05, mouth_height: 20.07, min*ratio: 4.02\n",
      "top_lip_height: 7.69, bottom_lip_height: 15.67, mouth_height: 16.40, min*ratio: 3.84\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "from mouth_open_algorithm import get_lip_height, get_mouth_height\n",
    "\n",
    "def is_mouth_open(face_landmarks):\n",
    "    top_lip = face_landmarks['top_lip']\n",
    "    bottom_lip = face_landmarks['bottom_lip']\n",
    "\n",
    "    top_lip_height = get_lip_height(top_lip)\n",
    "    bottom_lip_height = get_lip_height(bottom_lip)\n",
    "    mouth_height = get_mouth_height(top_lip, bottom_lip)\n",
    "\n",
    "    # if mouth is open more than lip height * ratio, return true.\n",
    "    ratio = 0.5\n",
    "    print('top_lip_height: %.2f, bottom_lip_height: %.2f, mouth_height: %.2f, min*ratio: %.2f' \n",
    "          % (top_lip_height, bottom_lip_height, mouth_height, min(top_lip_height, bottom_lip_height) * ratio))\n",
    "\n",
    "    return mouth_height > min(top_lip_height, bottom_lip_height) * ratio\n",
    "\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the codec and create VideoWriter object to save video to local\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # codec\n",
    "# cv2.VideoWriter( filename, fourcc, fps, frameSize )\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 7, (640, 480))\n",
    "\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    # Find all the faces and face encodings in the frame of video\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "\n",
    "    # Loop through each face in this frame of video\n",
    "    for (top, right, bottom, left), face_encoding, face_landmarks in zip(face_locations, face_encodings, face_landmarks_list):\n",
    "\n",
    "        # Check if this face is already in our known_face_encodings\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # If a match is found, use the name of the known face with the smallest distance\n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            name = known_face_names[first_match_index]\n",
    "\n",
    "        else:\n",
    "            # If no match is found, add the face encoding and name to our known faces\n",
    "            known_face_encodings.append(face_encoding)\n",
    "            known_face_names.append(\"Person {}\".format(len(known_face_names) + 1))\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom), (right, bottom + 35), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom + 25), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        # Display text for mouth open / close\n",
    "        ret_mouth_open = is_mouth_open(face_landmarks)\n",
    "        if ret_mouth_open:\n",
    "            text = 'Mouth is open'\n",
    "        else:\n",
    "            text = 'Mouth is closed'\n",
    "        cv2.putText(frame, text, (left, top - 50), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "    out.write(frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118627ac",
   "metadata": {},
   "source": [
    "# For Local Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5288dd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[2800]: Class FIFinderSyncExtensionHost is implemented in both /System/Library/PrivateFrameworks/FinderKit.framework/Versions/A/FinderKit (0x7fff9a870cd0) and /System/Library/PrivateFrameworks/FileProvider.framework/OverrideBundles/FinderSyncCollaborationFileProviderOverride.bundle/Contents/MacOS/FinderSyncCollaborationFileProviderOverride (0x12888dcd8). One of the two will be used. Which one is undefined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_lip_height: 10.43, bottom_lip_height: 14.73, mouth_height: 5.37, min*ratio: 5.21\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "import cv2\n",
    "from mouth_open_algorithm import get_lip_height, get_mouth_height\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Function to check if mouth is open\n",
    "def is_mouth_open(face_landmarks):\n",
    "    top_lip = face_landmarks['top_lip']\n",
    "    bottom_lip = face_landmarks['bottom_lip']\n",
    "\n",
    "    top_lip_height = get_lip_height(top_lip)\n",
    "    bottom_lip_height = get_lip_height(bottom_lip)\n",
    "    mouth_height = get_mouth_height(top_lip, bottom_lip)\n",
    "\n",
    "    # if mouth is open more than lip height * ratio, return true.\n",
    "    ratio = 0.5\n",
    "    print('top_lip_height: %.2f, bottom_lip_height: %.2f, mouth_height: %.2f, min*ratio: %.2f' \n",
    "          % (top_lip_height, bottom_lip_height, mouth_height, min(top_lip_height, bottom_lip_height) * ratio))\n",
    "\n",
    "    return mouth_height > min(top_lip_height, bottom_lip_height) * ratio\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        try:\n",
    "            # Load the image\n",
    "            img = cv2.imread(file_path)\n",
    "\n",
    "            # Find all the faces and face encodings in the image\n",
    "            face_locations = face_recognition.face_locations(img)\n",
    "            face_landmarks_list = face_recognition.face_landmarks(img)\n",
    "\n",
    "            # Loop through each face in the image\n",
    "            for (top, right, bottom, left), face_landmarks in zip(face_locations, face_landmarks_list):\n",
    "                # Draw a box around the face\n",
    "                cv2.rectangle(img, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "                # Display text for mouth open / close\n",
    "                ret_mouth_open = is_mouth_open(face_landmarks)\n",
    "                if ret_mouth_open:\n",
    "                    text = 'Mouth is open'\n",
    "                else:\n",
    "                    text = 'Mouth is closed'\n",
    "                cv2.putText(img, text, (left, top - 50), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "            # Display the resulting image\n",
    "            cv2.imshow('Image', img)\n",
    "            key = cv2.waitKey(0)  # Wait for a key press to proceed to the next image\n",
    "\n",
    "            # Check if 'q' key is pressed to exit\n",
    "            if key == ord('q'):\n",
    "                cv2.destroyAllWindows()\n",
    "        except Exception as e:\n",
    "            # Handle exceptions, e.g., display an error message\n",
    "            messagebox.showerror(\"Error\", \"Invalid Image\")\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Mouth Open Detector\")\n",
    "\n",
    "# Set background color\n",
    "window.configure(bg='#FAF9F6')\n",
    "\n",
    "# Set the initial size of the window\n",
    "window.geometry(\"700x600\")\n",
    "\n",
    "# Create widgets\n",
    "classify_button = tk.Button(window, text=\"Choose Image\", command=classify_image, fg='black')\n",
    "classify_button.pack(pady=50)\n",
    "\n",
    "# Run the main loop\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339c730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
